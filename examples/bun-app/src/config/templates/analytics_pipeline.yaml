---
# Data Pipeline Analytics (Blog Post 2)
# 8 steps with DAG pattern: 3 parallel extracts -> 3 transforms -> aggregate -> insights.

name: analytics_pipeline
namespace: default
version: "1.0.0"
description: "Multi-source analytics pipeline with parallel extraction, transformation, aggregation, and insight generation"

step_templates:
  # Layer 1: Parallel data extraction (no dependencies)
  - name: extract_sales_data
    description: "Extract sales transaction data from source systems"
    handler:
      callable: DataPipeline.StepHandlers.ExtractSalesDataHandler
      initialization: {}
    depends_on_step_name: []
    retry:
      max_attempts: 3
      backoff_strategy: exponential
      backoff_base_seconds: 5

  - name: extract_inventory_data
    description: "Extract inventory snapshots from warehouse management"
    handler:
      callable: DataPipeline.StepHandlers.ExtractInventoryDataHandler
      initialization: {}
    depends_on_step_name: []
    retry:
      max_attempts: 3
      backoff_strategy: exponential
      backoff_base_seconds: 5

  - name: extract_customer_data
    description: "Extract customer activity data from CRM"
    handler:
      callable: DataPipeline.StepHandlers.ExtractCustomerDataHandler
      initialization: {}
    depends_on_step_name: []
    retry:
      max_attempts: 3
      backoff_strategy: exponential
      backoff_base_seconds: 5

  # Layer 2: Parallel transformation (each depends on its extraction)
  - name: transform_sales
    description: "Transform sales data into category and time-series metrics"
    handler:
      callable: DataPipeline.StepHandlers.TransformSalesHandler
      initialization: {}
    depends_on_step_name:
      - extract_sales_data
    retry:
      max_attempts: 2
      backoff_strategy: exponential
      backoff_base_seconds: 3

  - name: transform_inventory
    description: "Transform inventory data into warehouse health scores"
    handler:
      callable: DataPipeline.StepHandlers.TransformInventoryHandler
      initialization: {}
    depends_on_step_name:
      - extract_inventory_data
    retry:
      max_attempts: 2
      backoff_strategy: exponential
      backoff_base_seconds: 3

  - name: transform_customer
    description: "Transform customer data into health and segment metrics"
    handler:
      callable: DataPipeline.StepHandlers.TransformCustomerHandler
      initialization: {}
    depends_on_step_name:
      - extract_customer_data
    retry:
      max_attempts: 2
      backoff_strategy: exponential
      backoff_base_seconds: 3

  # Layer 3: Aggregation (depends on all transforms)
  - name: aggregate_data
    description: "Aggregate cross-domain metrics and compute business health score"
    handler:
      callable: DataPipeline.StepHandlers.AggregateDataHandler
      initialization: {}
    depends_on_step_name:
      - transform_sales
      - transform_inventory
      - transform_customer
    retry:
      max_attempts: 2
      backoff_strategy: exponential
      backoff_base_seconds: 3

  # Layer 4: Insight generation (depends on aggregation)
  - name: generate_insights
    description: "Generate actionable business insights from aggregated data"
    handler:
      callable: DataPipeline.StepHandlers.GenerateInsightsHandler
      initialization: {}
    depends_on_step_name:
      - aggregate_data
    retry:
      max_attempts: 2
      backoff_strategy: exponential
      backoff_base_seconds: 3

input_schema:
  type: object
  properties:
    job_name:
      type: string
    sources:
      type: array
    parameters:
      type: object
    date_range:
      type: object
  required:
    - job_name
    - sources
